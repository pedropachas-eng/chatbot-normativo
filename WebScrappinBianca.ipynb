{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from urllib.parse import urlparse, urljoin\n",
        "from email.header import decode_header\n",
        "\n",
        "!pip -q install playwright\n",
        "from playwright.async_api import async_playwright, TimeoutError as PWTimeoutError\n",
        "\n",
        "!playwright install\n",
        "!playwright install-deps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sJNg8hgdlQjS",
        "outputId": "8dd1f218-8e21-4777-b2bd-38d538c5f0ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Get:2 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,592 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,864 kB]\n",
            "Fetched 12.5 MB in 2s (5,597 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo-gobject2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libdbus-glib-1-2 is already the newest version (0.112-2build1).\n",
            "libegl1 is already the newest version (1.4.0-1).\n",
            "libenchant-2-2 is already the newest version (2.3.2-1ubuntu2).\n",
            "libepoxy0 is already the newest version (1.5.10-1).\n",
            "libevdev2 is already the newest version (1.12.1+dfsg-1).\n",
            "libevent-2.1-7 is already the newest version (2.1.12-stable-1build3).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libgles2 is already the newest version (1.4.0-1).\n",
            "libglx0 is already the newest version (1.4.0-1).\n",
            "libgudev-1.0-0 is already the newest version (1:237-2build1).\n",
            "libhyphen0 is already the newest version (2.8.8-7build2).\n",
            "libicu70 is already the newest version (70.1-2).\n",
            "libjpeg-turbo8 is already the newest version (2.1.2-0ubuntu1).\n",
            "liblcms2-2 is already the newest version (2.12~rc1-2build2).\n",
            "libmanette-0.2-0 is already the newest version (0.2.6-3build1).\n",
            "libopengl0 is already the newest version (1.4.0-1).\n",
            "libopus0 is already the newest version (1.3.1-0.1build2).\n",
            "libproxy1v5 is already the newest version (0.4.17-2).\n",
            "libsecret-1-0 is already the newest version (0.20.5-2).\n",
            "libwoff1 is already the newest version (1.0.2-1build4).\n",
            "libxcb-shm0 is already the newest version (1.14-3ubuntu3).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxcursor1 is already the newest version (1:1.2.0-2build4).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxi6 is already the newest version (2:1.8-1build1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "libxrender1 is already the newest version (1:0.9.10-1build4).\n",
            "libxtst6 is already the newest version (2:1.2.3-1build4).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "libavif13 is already the newest version (0.9.3-3).\n",
            "libffi7 is already the newest version (3.3-5ubuntu1).\n",
            "libx264-163 is already the newest version (2:0.163.3060+git5db6aa6-2build1).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.047-0ubuntu0.22.04.1).\n",
            "gstreamer1.0-plugins-base is already the newest version (1.20.1-1ubuntu0.5).\n",
            "gstreamer1.0-plugins-good is already the newest version (1.20.3-0ubuntu1.4).\n",
            "libatomic1 is already the newest version (12.3.0-1ubuntu1~22.04.2).\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.16).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.3).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libgdk-pixbuf-2.0-0 is already the newest version (2.42.8+dfsg-1ubuntu0.4).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.7).\n",
            "libgstreamer-gl1.0-0 is already the newest version (1.20.1-1ubuntu0.5).\n",
            "libgstreamer-plugins-base1.0-0 is already the newest version (1.20.1-1ubuntu0.5).\n",
            "libgstreamer1.0-0 is already the newest version (1.20.3-0ubuntu1.1).\n",
            "libgtk-3-0 is already the newest version (3.24.33-1ubuntu2.2).\n",
            "libgtk-4-1 is already the newest version (4.6.9+ds-0ubuntu0.22.04.2).\n",
            "libharfbuzz-icu0 is already the newest version (2.7.4-1ubuntu3.2).\n",
            "libharfbuzz0b is already the newest version (2.7.4-1ubuntu3.2).\n",
            "libnotify4 is already the newest version (0.7.9-3ubuntu5.22.04.1).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libopenjp2-7 is already the newest version (2.4.0-6ubuntu0.4).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpangocairo-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpng16-16 is already the newest version (1.6.37-3ubuntu0.1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libwayland-egl1 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libwayland-server0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libwebpdemux2 is already the newest version (1.2.2-2ubuntu0.22.04.2).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libx11-xcb1 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libxml2 is already the newest version (2.9.13+dfsg-1ubuntu0.10).\n",
            "libxslt1.1 is already the newest version (1.1.34-4ubuntu0.22.04.5).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "gstreamer1.0-libav is already the newest version (1.20.3-0ubuntu1).\n",
            "gstreamer1.0-plugins-bad is already the newest version (1.20.3-0ubuntu1.1).\n",
            "libsoup-3.0-0 is already the newest version (3.0.7-0ubuntu1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.16).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE = \"https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/{}\"\n",
        "OUT_DIR = \"/content/drive/MyDrive/Maestria UNI/PLN/TrabajoFinal/senace_normas\"\n",
        "START_ID = 100\n",
        "END_ID = 500"
      ],
      "metadata": {
        "id": "ShF_6aYub7xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwMV4j1nON71"
      },
      "outputs": [],
      "source": [
        "def safe_filename(name: str) -> str:\n",
        "    name = re.sub(r\"[\\\\/*?:\\\"<>|]\", \"_\", name)\n",
        "    name = re.sub(r\"\\s+\", \" \", name).strip()\n",
        "    return name[:180] if len(name) > 180 else name\n",
        "\n",
        "\n",
        "def guess_ext_from_url(url: str) -> str:\n",
        "    path = urlparse(url).path.lower()\n",
        "    if path.endswith(\".pdf\"):\n",
        "        return \".pdf\"\n",
        "    if path.endswith(\".doc\"):\n",
        "        return \".doc\"\n",
        "    if path.endswith(\".docx\"):\n",
        "        return \".docx\"\n",
        "    if path.endswith(\".xls\"):\n",
        "        return \".xls\"\n",
        "    if path.endswith(\".xlsx\"):\n",
        "        return \".xlsx\"\n",
        "    # SENACE /download suele devolver PDF sin extensión en la URL\n",
        "    return \".pdf\"\n",
        "\n",
        "\n",
        "def decode_mime_word(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Decodifica nombres tipo =?utf-8?B?...?= o =_utf-8_B_..._=\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # normaliza el formato raro con guiones bajos\n",
        "        s = s.replace(\"=_utf-8_B_\", \"=?utf-8?B?\").replace(\"_=\", \"?=\")\n",
        "\n",
        "        parts = decode_header(s)\n",
        "        decoded = \"\"\n",
        "        for text, charset in parts:\n",
        "            if isinstance(text, bytes):\n",
        "                decoded += text.decode(charset or \"utf-8\", errors=\"ignore\")\n",
        "            else:\n",
        "                decoded += text\n",
        "        return decoded\n",
        "    except Exception:\n",
        "        return s\n",
        "\n",
        "\n",
        "def pick_filename_from_headers(headers: dict, fallback_name: str, url: str) -> str:\n",
        "    \"\"\"\n",
        "    Obtiene el nombre real desde Content-Disposition.\n",
        "    Si viene codificado, lo decodifica.\n",
        "    Si no existe, usa fallback + extensión inferida.\n",
        "    \"\"\"\n",
        "    cd = \"\"\n",
        "    for k, v in headers.items():\n",
        "        if k.lower() == \"content-disposition\":\n",
        "            cd = v\n",
        "            break\n",
        "\n",
        "    if cd:\n",
        "        # filename* (UTF-8 moderno RFC5987)\n",
        "        m = re.search(r'filename\\*=(?:UTF-8\\'\\')?([^;]+)', cd, flags=re.I)\n",
        "        if m:\n",
        "            name = decode_mime_word(m.group(1).strip('\"'))\n",
        "            return safe_filename(name)\n",
        "\n",
        "        # filename clásico\n",
        "        m = re.search(r'filename=\"?([^\";]+)\"?', cd, flags=re.I)\n",
        "        if m:\n",
        "            name_raw = m.group(1)\n",
        "            name = decode_mime_word(name_raw)\n",
        "            return safe_filename(name)\n",
        "\n",
        "    # fallback\n",
        "    ext = guess_ext_from_url(url)\n",
        "    name = safe_filename(fallback_name) or \"archivo\"\n",
        "    if not re.search(r\"\\.(pdf|docx?|xlsx?)$\", name, flags=re.I):\n",
        "        name += ext\n",
        "    return name\n",
        "\n",
        "\n",
        "async def download_file(context, file_url: str, dest_folder: str,\n",
        "                        referer: str, link_text: str,\n",
        "                        norma_id: int | None = None,\n",
        "                        file_index: int | None = None):\n",
        "    \"\"\"\n",
        "    Descarga el pdf\n",
        "    \"\"\"\n",
        "\n",
        "    # Petición HTTP al endpoint /download\n",
        "    resp = await context.request.get(\n",
        "        file_url,\n",
        "        timeout=90000,\n",
        "        headers={\"Referer\": referer}\n",
        "    )\n",
        "    if not resp.ok:\n",
        "        raise Exception(f\"HTTP {resp.status} descargando {file_url}\")\n",
        "\n",
        "    # 1) Nombre base: texto del link\n",
        "    base_name = (link_text or \"\").strip()\n",
        "    if not base_name:\n",
        "        base_name = \"archivo\"\n",
        "\n",
        "    base_name = safe_filename(base_name)\n",
        "\n",
        "    # 2) Asegurar extensión\n",
        "    if not re.search(r\"\\.(pdf|docx?|xlsx?)$\", base_name, flags=re.I):\n",
        "        # Por URL\n",
        "        ext = guess_ext_from_url(file_url)\n",
        "\n",
        "        # Mejorar por Content-Type si es posible\n",
        "        ct = (resp.headers.get(\"content-type\") or \"\").lower()\n",
        "        if \"pdf\" in ct:\n",
        "            ext = \".pdf\"\n",
        "        elif \"msword\" in ct or \"word\" in ct:\n",
        "            ext = \".doc\"\n",
        "        elif \"spreadsheet\" in ct or \"excel\" in ct:\n",
        "            ext = \".xlsx\"\n",
        "\n",
        "        base_name += ext\n",
        "\n",
        "    filename = base_name\n",
        "\n",
        "    # 3) Prefijo opcional con ID e índice (para distinguir archivos)\n",
        "    if norma_id is not None:\n",
        "        name_body, ext = os.path.splitext(filename)\n",
        "        if file_index is not None:\n",
        "            filename = f\"{norma_id}_{file_index}_{name_body}{ext}\"\n",
        "        else:\n",
        "            filename = f\"{norma_id}_{name_body}{ext}\"\n",
        "\n",
        "    dest = os.path.join(dest_folder, filename)\n",
        "\n",
        "    # 4) Guardar bytes\n",
        "    with open(dest, \"wb\") as wf:\n",
        "        wf.write(await resp.body())\n",
        "\n",
        "    return dest\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "async def click_tab_if_exists(page, tab_text: str):\n",
        "    \"\"\"\n",
        "    Click en tab por texto si existe. No revienta si no está.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        loc = page.locator(\"ul.nav.nav-tabs\").locator(f\"text={tab_text}\")\n",
        "        if await loc.count() > 0:\n",
        "            await loc.first.click(timeout=6000)\n",
        "            await page.wait_for_timeout(800)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "\n",
        "async def robust_wait_norma_loaded(page, timeout_ms: int = 90000):\n",
        "    \"\"\"\n",
        "    Espera robusta para Angular SPA:\n",
        "    - Espera tabs\n",
        "    - Espera que haya texto real en algún bloque .norma-info-item .body\n",
        "    - Espera que body tenga suficiente texto visible\n",
        "    \"\"\"\n",
        "    await page.wait_for_selector(\"ul.nav.nav-tabs\", timeout=timeout_ms)\n",
        "\n",
        "    await page.wait_for_function(\n",
        "        \"\"\"\n",
        "        () => {\n",
        "            const bodies = Array.from(document.querySelectorAll('.norma-info-item .body'));\n",
        "            return bodies.length > 0 && bodies.some(b => (b.innerText || '').trim().length > 5);\n",
        "        }\n",
        "        \"\"\",\n",
        "        timeout=timeout_ms\n",
        "    )\n",
        "\n",
        "    await page.wait_for_function(\n",
        "        \"\"\"\n",
        "        () => {\n",
        "            const t = (document.body?.innerText || '').trim();\n",
        "            return t.length > 80;\n",
        "        }\n",
        "        \"\"\",\n",
        "        timeout=timeout_ms\n",
        "    )\n",
        "\n",
        "\n",
        "async def extract_meta(page) -> dict:\n",
        "    \"\"\"\n",
        "    Extrae metadatos con selectores mejorados para capturar 'Temas'\n",
        "    y filtrar elementos irrelevantes (Exportar/Compartir).\n",
        "    \"\"\"\n",
        "    #await page.wait_for_selector('[class^=\"norma-info-items\"]', timeout=12000)\n",
        "    await page.wait_for_selector('.norma-info-item', timeout=20000)\n",
        "\n",
        "\n",
        "    return await page.evaluate(\"\"\"\n",
        "    () => {\n",
        "      const out = {};\n",
        "      // Buscamos todos los bloques de información\n",
        "      const items = document.querySelectorAll('.norma-info-item .body');\n",
        "\n",
        "      items.forEach(body => {\n",
        "        const labelEl = body.querySelector('label.title');\n",
        "        if (!labelEl) return;\n",
        "\n",
        "        const label = labelEl.innerText.replace(':', '').trim();\n",
        "\n",
        "        // Intentamos obtener el texto de .info-txt\n",
        "        // o de cualquier div/span que siga al label (para casos especiales de Angular)\n",
        "        let valueEl = body.querySelector('.info-txt');\n",
        "\n",
        "        // Si no existe .info-txt, buscamos el siguiente elemento hermano del label\n",
        "        if (!valueEl) {\n",
        "            valueEl = labelEl.nextElementSibling;\n",
        "        }\n",
        "\n",
        "        if (valueEl) {\n",
        "            let text = valueEl.innerText.trim();\n",
        "\n",
        "            // Si el texto está vacío pero hay una lista (como en Sugerencias),\n",
        "            // no lo agregamos, o lo procesamos distinto.\n",
        "            // Para 'Temas', esto asegura capturar el texto plano.\n",
        "            if (label && text.length > 0) {\n",
        "                out[label] = text;\n",
        "            }\n",
        "        }\n",
        "      });\n",
        "      return out;\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "async def extract_header_optional(page) -> tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Extrae lbltituloNorma / lblNorma si existen (sin bloquear).\n",
        "    \"\"\"\n",
        "    titulo_norma = \"\"\n",
        "    codigo_norma = \"\"\n",
        "\n",
        "    lbl1 = page.locator(\"#lbltituloNorma\")\n",
        "    if await lbl1.count() > 0:\n",
        "        titulo_norma = (await lbl1.first.inner_text()).strip()\n",
        "\n",
        "    lbl2 = page.locator(\"#lblNorma\")\n",
        "    if await lbl2.count() > 0:\n",
        "        codigo_norma = (await lbl2.first.inner_text()).strip()\n",
        "\n",
        "    return titulo_norma, codigo_norma\n",
        "\n",
        "\n",
        "async def extract_texto_completo(page) -> str:\n",
        "    \"\"\"\n",
        "    Intenta extraer el texto completo:\n",
        "    - preferir nodos [id^=\"article\"] (cuando existen)\n",
        "    - fallback: texto general del body\n",
        "    \"\"\"\n",
        "    # Asegurar tab \"Texto completo\" si existe\n",
        "    await click_tab_if_exists(page, \"Texto completo\")\n",
        "\n",
        "    # 1) Extraer H1 (ordenados como aparecen en el DOM)\n",
        "    h1_texts = await page.eval_on_selector_all(\n",
        "        \"h1\",\n",
        "        \"\"\"\n",
        "        els => els\n",
        "          .map(e => (e.innerText || '').trim())\n",
        "          .filter(t => t.length > 0)\n",
        "        \"\"\"\n",
        "    )\n",
        "    codigo_norma = h1_texts[0] if len(h1_texts) >= 1 else \"\"\n",
        "    titulo_norma = h1_texts[1] if len(h1_texts) >= 2 else \"\"\n",
        "\n",
        "    # 2) Extraer cuerpo del texto\n",
        "    articles_text = \"\"\n",
        "    try:\n",
        "        # Algunos casos tardan en generar los article_*\n",
        "        await page.wait_for_selector('[id^=\"norma-view\"]', timeout=12000)\n",
        "        articles_text = await page.eval_on_selector_all(\n",
        "            '[id^=\"norma-view\"]',\n",
        "            \"\"\"\n",
        "            els => els\n",
        "              .map(e => (e.innerText || '').trim())\n",
        "              .filter(t => t.length > 0)\n",
        "              .join('\\\\n\\\\n')\n",
        "            \"\"\"\n",
        "        )\n",
        "    except PWTimeoutError:\n",
        "        articles_text = \"\"\n",
        "\n",
        "    full_text = await page.evaluate(\"() => (document.body.innerText || '').trim()\")\n",
        "    # return articles_text if len(articles_text) >= 80 else full_text\n",
        "    cuerpo = articles_text if len(articles_text) >= 80 else full_text\n",
        "\n",
        "    return codigo_norma, titulo_norma, cuerpo\n",
        "\n",
        "\n",
        "from urllib.parse import urljoin  # asegúrate de tener esto importado\n",
        "\n",
        "async def download_archivos_tab(page, context, norma_folder: str,\n",
        "                                referer_url: str, norma_id: int):\n",
        "\n",
        "    try:\n",
        "        tab_archivos = page.locator(\"ul.nav.nav-tabs >> text=Archivos\")\n",
        "        if await tab_archivos.count() > 0:\n",
        "            await tab_archivos.first.scroll_into_view_if_needed()\n",
        "            await tab_archivos.first.click(timeout=8000)\n",
        "        else:\n",
        "            # Fallback: texto \"Archivos\" en cualquier lado\n",
        "            tab_archivos = page.locator(\"text=Archivos\")\n",
        "            if await tab_archivos.count() > 0:\n",
        "                await tab_archivos.first.scroll_into_view_if_needed()\n",
        "                await tab_archivos.first.click(timeout=8000)\n",
        "    except Exception:\n",
        "        pass  # si no se puede clickear igual seguimos\n",
        "\n",
        "    await page.wait_for_timeout(1500)\n",
        "\n",
        "    # 2) Buscar TODOS los links de descarga en la página\n",
        "    archivos = await page.eval_on_selector_all(\n",
        "        \"a[href*='/NormasAmbientales/api/documentos/'][href*='/download']\",\n",
        "        \"\"\"\n",
        "        els => els.map((a, i) => ({\n",
        "          href: a.href,\n",
        "          text: (a.innerText || a.textContent || '').trim(),\n",
        "          idx: i + 1\n",
        "        })).filter(x => x.href)\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    if not archivos:\n",
        "        print(\"  -> No se encontraron archivos de descarga (ningún href con /NormasAmbientales/api/documentos/.../download)\")\n",
        "        return\n",
        "\n",
        "    # Quitar duplicados\n",
        "    seen = set()\n",
        "    archivos_clean = []\n",
        "    for a in archivos:\n",
        "        if a[\"href\"] not in seen:\n",
        "            seen.add(a[\"href\"])\n",
        "            archivos_clean.append(a)\n",
        "\n",
        "    files_folder = os.path.join(norma_folder, \"archivos\")\n",
        "    os.makedirs(files_folder, exist_ok=True)\n",
        "\n",
        "    print(f\"  -> Archivos encontrados: {len(archivos_clean)}\")\n",
        "    # DEBUG: ver textos reales de los links\n",
        "    for a in archivos_clean:\n",
        "        print(f\"     Link: {a['href']}  |  Texto: {a['text']}\")\n",
        "\n",
        "    # 3) Descargar\n",
        "    for idx, a in enumerate(archivos_clean, start=1):\n",
        "        href = a[\"href\"]\n",
        "        text = a[\"text\"] or f\"archivo_{idx}\"\n",
        "\n",
        "        absolute_url = urljoin(referer_url, href)\n",
        "\n",
        "        try:\n",
        "            saved = await download_file(\n",
        "                context=context,\n",
        "                file_url=absolute_url,\n",
        "                dest_folder=files_folder,\n",
        "                referer=referer_url,\n",
        "                link_text=text,\n",
        "                norma_id=norma_id,\n",
        "                file_index=idx\n",
        "            )\n",
        "            print(f\"     Descargado: {os.path.basename(saved)}\")\n",
        "        except Exception as e:\n",
        "            print(f\"     Error descargando {absolute_url}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "    # 1. Initialize an empty list\n",
        "    all_normas_data = []\n",
        "\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(\n",
        "            headless=True,\n",
        "            args=[\"--disable-blink-features=AutomationControlled\"],\n",
        "        )\n",
        "\n",
        "        context = await browser.new_context(\n",
        "            locale=\"es-PE\",\n",
        "            user_agent=(\n",
        "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "                \"Chrome/120.0.0.0 Safari/537.36\"\n",
        "            ),\n",
        "            viewport={\"width\": 1400, \"height\": 900},\n",
        "        )\n",
        "\n",
        "        async def block_heavy(route):\n",
        "            if route.request.resource_type in (\"image\", \"font\"):\n",
        "                await route.abort()\n",
        "            else:\n",
        "                await route.continue_()\n",
        "\n",
        "        await context.route(\"**/*\", block_heavy)\n",
        "\n",
        "        for norma_id in range(START_ID, END_ID + 1):\n",
        "            url = BASE.format(norma_id)\n",
        "            norma_folder = os.path.join(OUT_DIR, str(norma_id))\n",
        "            os.makedirs(norma_folder, exist_ok=True)\n",
        "\n",
        "            print(f\"\\n[{norma_id}] {url}\")\n",
        "\n",
        "            page = await context.new_page()\n",
        "            try:\n",
        "\n",
        "                await page.goto(url, wait_until=\"domcontentloaded\", timeout=90000)\n",
        "\n",
        "                await robust_wait_norma_loaded(page, timeout_ms=90000)\n",
        "\n",
        "\n",
        "                # titulo_norma, codigo_norma = await extract_header_optional(page)\n",
        "\n",
        "\n",
        "\n",
        "                # Meta\n",
        "                meta = await extract_meta(page)\n",
        "                fecha_publicacion = meta.get(\"Fecha de publicación\", \"\")\n",
        "                organismo = meta.get(\"Organismo\", \"\")\n",
        "                estado = meta.get(\"Estado\", \"\")\n",
        "                temas = meta.get(\"Temas\", \"\")\n",
        "\n",
        "                # Texto completo\n",
        "                # cuerpo_texto = await extract_texto_completo(page)\n",
        "                codigo_h1, titulo_h1, cuerpo_texto = await extract_texto_completo(page)\n",
        "                if not cuerpo_texto or len(cuerpo_texto) < 80:\n",
        "                    print(\"  -> No se encontró texto suficiente\")\n",
        "                    await page.close()\n",
        "                    continue\n",
        "\n",
        "                # 3a. Create dictionary and populate it with extracted metadata\n",
        "                norma_data = {\n",
        "                    \"id\": norma_id,\n",
        "                    \"titulo\": titulo_h1,\n",
        "                    \"codigo\": codigo_h1,\n",
        "                    \"fecha_publicacion\": fecha_publicacion,\n",
        "                    \"organismo\": organismo,\n",
        "                    \"estado\": estado,\n",
        "                    \"temas\": temas\n",
        "                }\n",
        "\n",
        "                # Guardar TXT\n",
        "                final_text = (\n",
        "                    f\"TÍTULO:\\n{titulo_h1}\\n\\n\"\n",
        "                    f\"NORMA:\\n{codigo_h1}\\n\\n\"\n",
        "                    f\"FECHA DE PUBLICACIÓN:\\n{fecha_publicacion}\\n\\n\"\n",
        "                    f\"ORGANISMO:\\n{organismo}\\n\\n\"\n",
        "                    f\"ESTADO:\\n{estado}\\n\\n\"\n",
        "                    f\"TEMAS:\\n{temas}\\n\\n\"\n",
        "                    f\"{'-' * 60}\\n\\n\"\n",
        "                    f\"{cuerpo_texto}\\n\"\n",
        "                )\n",
        "\n",
        "                txt_path = os.path.join(norma_folder, f\"norma_{norma_id}.txt\")\n",
        "                with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(final_text)\n",
        "\n",
        "                # Guardar JSON\n",
        "                json_path = os.path.join(norma_folder, f\"norma_{norma_id}.json\")\n",
        "                with open(json_path, \"w\", encoding=\"utf-8\") as jf:\n",
        "                    json.dump({\n",
        "                        \"id\": norma_id,\n",
        "                        \"titulo\": titulo_h1,\n",
        "                        \"codigo\": codigo_h1,\n",
        "                        \"fecha_publicacion\": fecha_publicacion,\n",
        "                        \"organismo\": organismo,\n",
        "                        \"estado\": estado,\n",
        "                        \"temas\": temas,\n",
        "                        \"url\": url\n",
        "                    }, jf, ensure_ascii=False, indent=2)\n",
        "\n",
        "                print(\"  -> TXT y JSON guardados\")\n",
        "\n",
        "                all_normas_data.append(norma_data)\n",
        "\n",
        "                await download_archivos_tab(\n",
        "                    page,\n",
        "                    context,\n",
        "                    norma_folder,\n",
        "                    referer_url=url,\n",
        "                    norma_id=norma_id,\n",
        "                )\n",
        "\n",
        "            except PWTimeoutError as e:\n",
        "                print(f\"  !! Timeout cargando la norma: {e}\")\n",
        "            except Exception as e:\n",
        "                print(f\"  !! Error: {e}\")\n",
        "            finally:\n",
        "                await page.close()\n",
        "\n",
        "        await browser.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    await main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUDhs4u1ctf4",
        "outputId": "9479ccf5-3350-496b-f6c3-1f119047f391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[121] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/121\n",
            "  -> TXT y JSON guardados\n",
            "  -> No se encontraron archivos de descarga (ningún href con /NormasAmbientales/api/documentos/.../download)\n",
            "\n",
            "[122] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/122\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/97/download  |  Texto: EXP-DS-002-2021-MINAM EXPOSICION DE MOTIVOS.pdf\n",
            "     Descargado: 122_1_EXP-DS-002-2021-MINAM EXPOSICION DE MOTIVOS.pdf\n",
            "\n",
            "[123] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/123\n",
            "  !! Timeout cargando la norma: Page.wait_for_function: Timeout 90000ms exceeded.\n",
            "\n",
            "[124] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/124\n",
            "  -> TXT y JSON guardados\n",
            "  -> No se encontraron archivos de descarga (ningún href con /NormasAmbientales/api/documentos/.../download)\n",
            "\n",
            "[125] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/125\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/383/download  |  Texto: ANEXO_Resolución Jefatural N° 060-2017-SENACE-J.pdf\n",
            "     Descargado: 125_1_ANEXO_Resolución Jefatural N° 060-2017-SENACE-J.pdf\n",
            "\n",
            "[126] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/126\n",
            "  -> TXT y JSON guardados\n",
            "  -> No se encontraron archivos de descarga (ningún href con /NormasAmbientales/api/documentos/.../download)\n",
            "\n",
            "[127] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/127\n",
            "  !! Timeout cargando la norma: Page.wait_for_selector: Timeout 90000ms exceeded.\n",
            "Call log:\n",
            "  - waiting for locator(\"ul.nav.nav-tabs\") to be visible\n",
            "\n",
            "\n",
            "[128] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/128\n",
            "  -> TXT y JSON guardados\n",
            "  -> No se encontraron archivos de descarga (ningún href con /NormasAmbientales/api/documentos/.../download)\n",
            "\n",
            "[129] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/129\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/394/download  |  Texto: ANEXO Res Jef 008 2018 JEF.pdf\n",
            "     Descargado: 129_1_ANEXO Res Jef 008 2018 JEF.pdf\n",
            "\n",
            "[130] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/130\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/393/download  |  Texto: Anexo RPE 00005-2018-SENACE-PE.pdf\n",
            "     Descargado: 130_1_Anexo RPE 00005-2018-SENACE-PE.pdf\n",
            "\n",
            "[131] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/131\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/101/download  |  Texto: RPE_00050- 2020-SENACE-PE (Criterios técnicos-legales).pdf\n",
            "     Descargado: 131_1_RPE_00050- 2020-SENACE-PE (Criterios técnicos-legales).pdf\n",
            "\n",
            "[132] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/132\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/102/download  |  Texto: RPE 00082-2020-SENACE-PE (Guía Metodológico).pdf\n",
            "     Descargado: 132_1_RPE 00082-2020-SENACE-PE (Guía Metodológico).pdf\n",
            "\n",
            "[133] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/133\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 3\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/558/download  |  Texto: PL02568_19970311.pdf\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/559/download  |  Texto: PL02746_19970522.pdf\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/560/download  |  Texto: Dictamen_Comisión de Ambiente, Ecología y Amazonia.pdf\n",
            "     Descargado: 133_1_PL02568_19970311.pdf\n",
            "     Descargado: 133_2_PL02746_19970522.pdf\n",
            "     Descargado: 133_3_Dictamen_Comisión de Ambiente, Ecología y Amazonia.pdf\n",
            "\n",
            "[134] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/134\n",
            "  -> TXT y JSON guardados\n",
            "  -> No se encontraron archivos de descarga (ningún href con /NormasAmbientales/api/documentos/.../download)\n",
            "\n",
            "[135] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/135\n",
            "  !! Timeout cargando la norma: Page.wait_for_function: Timeout 90000ms exceeded.\n",
            "\n",
            "[136] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/136\n",
            "  -> TXT y JSON guardados\n",
            "  -> No se encontraron archivos de descarga (ningún href con /NormasAmbientales/api/documentos/.../download)\n",
            "\n",
            "[137] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/137\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/496/download  |  Texto: Informe de Sustento_Ley 30230.pdf\n",
            "     Descargado: 137_1_Informe de Sustento_Ley 30230.pdf\n",
            "\n",
            "[138] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/138\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 3\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/352/download  |  Texto: DS-014-2017-MINAM -EXPOSICIÓN DE MOTIVOS.pdf\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/353/download  |  Texto: DS-014-2017-MINAM -CUADRO DE TIPIFICACIÓN.pdf\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/709/download  |  Texto: Matriz de comentarios al DS N° 014-2017-MINAM.pdf\n",
            "     Descargado: 138_1_DS-014-2017-MINAM -EXPOSICIÓN DE MOTIVOS.pdf\n",
            "     Descargado: 138_2_DS-014-2017-MINAM -CUADRO DE TIPIFICACIÓN.pdf\n",
            "     Descargado: 138_3_Matriz de comentarios al DS N° 014-2017-MINAM.pdf\n",
            "\n",
            "[139] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/139\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/726/download  |  Texto: Exposición de Motivos - DS N° 038-2001-AG.pdf\n",
            "     Descargado: 139_1_Exposición de Motivos - DS N° 038-2001-AG.pdf\n",
            "\n",
            "[140] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/140\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 3\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/335/download  |  Texto: DS-001-2022-MINAM EXPOSICIÓN DE MOTIVOS.pdf\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/336/download  |  Texto: DS-001-2022-MINAM CUADRO DE INFRACCIONES.pdf\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/710/download  |  Texto: MATRIZ DE COMENTARIOS - DS N° 001-2022-MINAM.pdf\n",
            "     Descargado: 140_1_DS-001-2022-MINAM EXPOSICIÓN DE MOTIVOS.pdf\n",
            "     Descargado: 140_2_DS-001-2022-MINAM CUADRO DE INFRACCIONES.pdf\n",
            "     Descargado: 140_3_MATRIZ DE COMENTARIOS - DS N° 001-2022-MINAM.pdf\n",
            "\n",
            "[141] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/141\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/113/download  |  Texto: EXP-DS-015-2007-AG EXPOSICION DE MOTIVOS.PDF\n",
            "     Descargado: 141_1_EXP-DS-015-2007-AG EXPOSICION DE MOTIVOS.PDF\n",
            "\n",
            "[142] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/142\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/239/download  |  Texto: EXP MOT-DS-018-2009-MINAM.pdf\n",
            "     Descargado: 142_1_EXP MOT-DS-018-2009-MINAM.pdf\n",
            "\n",
            "[143] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/143\n",
            "  !! Timeout cargando la norma: Page.wait_for_selector: Timeout 20000ms exceeded.\n",
            "Call log:\n",
            "  - waiting for locator(\".norma-info-item\") to be visible\n",
            "\n",
            "\n",
            "[144] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/144\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/115/download  |  Texto: EXP-DS-003-2011-MINAM EXPOSICION DE MOTIVOS.pdf\n",
            "     Descargado: 144_1_EXP-DS-003-2011-MINAM EXPOSICION DE MOTIVOS.pdf\n",
            "\n",
            "[145] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/145\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 2\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/116/download  |  Texto: EXP-DS-007-2011-MINAM EXPOSICION DE MOTIVOS.pdf\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/241/download  |  Texto: EXP-DS-007-2011-MINAM EXPOSICIÓN DE MOTIVOS.pdf\n",
            "     Descargado: 145_1_EXP-DS-007-2011-MINAM EXPOSICION DE MOTIVOS.pdf\n",
            "     Descargado: 145_2_EXP-DS-007-2011-MINAM EXPOSICIÓN DE MOTIVOS.pdf\n",
            "\n",
            "[146] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/146\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 1\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/118/download  |  Texto: EXP-DS-010-2015-MINAM EXPOSICION DE MOTIVOS.pdf\n",
            "     Descargado: 146_1_EXP-DS-010-2015-MINAM EXPOSICION DE MOTIVOS.pdf\n",
            "\n",
            "[147] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/147\n",
            "  -> TXT y JSON guardados\n",
            "  -> Archivos encontrados: 2\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/120/download  |  Texto: EXP-DS-026-2021-MINAM EXPOSICIÓN DE MOTIVOS.pdf\n",
            "     Link: https://enlinea.senace.gob.pe/NormasAmbientales/api/documentos/714/download  |  Texto: MATRIZ DE COMENTARIOS - DS N° 026-2021-MINAM.pdf\n",
            "     Descargado: 147_1_EXP-DS-026-2021-MINAM EXPOSICIÓN DE MOTIVOS.pdf\n",
            "     Descargado: 147_2_MATRIZ DE COMENTARIOS - DS N° 026-2021-MINAM.pdf\n",
            "\n",
            "[148] https://enlinea.senace.gob.pe/BuscadorNormas/#/norma/148\n"
          ]
        }
      ]
    }
  ]
}
